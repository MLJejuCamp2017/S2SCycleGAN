{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import wave\n",
    "import glob\n",
    "import scipy.io.wavfile as wavfile\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global SMP_RATE\n",
    "SMP_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWaveName(wavepath):\n",
    "    return wavepath.split('/')[-1]\n",
    "\n",
    "def findWave(wavefile,path):\n",
    "    r = glob.glob(path+wavefile)\n",
    "    return r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpath = '../../cmu_artic/female_us_slt/' #desktop\n",
    "mpath = '../../cmu_artic/male_us_bdl/' #desktop\n",
    "# fpath = '../data/female_us/'\n",
    "# mpath = '../data/male_us/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map male to female\n",
    "m2f = dict()\n",
    "for i in glob.glob(mpath+'/*.wav'):\n",
    "    m2f[i]=findWave(getWaveName(i),fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_size_x = (2,3)\n",
    "bin_size_y = (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_mapping = {}\n",
    "for filename in glob.glob(mpath+'*.wav'):\n",
    "    fm, wav_data = wavfile.read(filename)\n",
    "    size = wav_data.shape[0]/(1.0*fm)\n",
    "    if size < bin_size_x[1] and size > bin_size_x[0]:\n",
    "        fm2, wav_data2 = wavfile.read(m2f[filename])\n",
    "        size2 = wav_data2.shape[0]/(1.0*fm2)\n",
    "        if size2 < bin_size_x[1] and size2 > bin_size_x[0]:\n",
    "            bin_mapping[filename] = m2f[filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padTo(x,size,kind='SYM'):\n",
    "    \"\"\"\n",
    "    Expects 1D array\n",
    "    \"\"\"\n",
    "    assert kind in ['LEFT','RIGHT','SYM']\n",
    "    if kind == 'LEFT':\n",
    "        pad = np.zeros(size-len(x),dtype=x.dtype)\n",
    "        r=np.concatenate((pad,x),axis=0)\n",
    "    elif kind == 'RIGHT':\n",
    "        pad = np.zeros(size-len(x),dtype=x.dtype)\n",
    "        r=np.concatenate((x,pad),axis=0)\n",
    "    elif kind == 'SYM':\n",
    "        padl = np.zeros((size-len(x))/2,dtype=x.dtype)\n",
    "        padr = np.zeros((size-len(x))/2+(size-len(x))%2,dtype=x.dtype)\n",
    "        r = np.concatenate((padl,x,padr),axis=0)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Batch(object):\n",
    "    def __init__(self,mapping,bin_max,batch_size=1):\n",
    "        self.mapping = mapping\n",
    "        self.bin_max = bin_max\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_size = self.bin_max*SMP_RATE\n",
    "        self.shape = (self.batch_size,1,self.seq_size,1)\n",
    "        self.x_list = mapping.keys()\n",
    "        self.size = len(self.x_list) #data size\n",
    "        self.cursors = [(self.size//self.batch_size)*i for i in range(self.batch_size)]\n",
    "        \n",
    "    def getBatch(self):\n",
    "        #get the file names\n",
    "        x_path = [self.x_list[c] for c in self.cursors]\n",
    "        y_path = [self.mapping[xp] for xp in x_path]\n",
    "        \n",
    "        #Get the x,y files and pad\n",
    "        x = np.empty(shape=(self.batch_size,1,self.seq_size,1))\n",
    "        y = np.empty(shape=(self.batch_size,1,self.seq_size,1))\n",
    "        for i,(xp,yp) in enumerate(zip(x_path,y_path)):\n",
    "            _,x_raw=wavfile.read(xp)\n",
    "            _,y_raw=wavfile.read(yp)\n",
    "            x_pad = padTo(x_raw,self.bin_max*SMP_RATE)\n",
    "            y_pad = padTo(y_raw,self.bin_max*SMP_RATE)\n",
    "            x[i,0,:,0]=x_pad\n",
    "            y[i,0,:,0]=y_pad\n",
    "            \n",
    "        #update cursor positions\n",
    "        self.cursors = [(c+1)%self.size for c in self.cursors]\n",
    "        return (x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prelu(x,name='prelu'):\n",
    "    in_shape = x.get_shape().as_list()\n",
    "    with tf.variable_scope(name):\n",
    "        alpha = tf.get_variable('alpha',in_shape[-1],\n",
    "                               initializer=tf.constant_initializer(0.),\n",
    "                               dtype=tf.float32)\n",
    "        pos = tf.nn.relu(x)\n",
    "        neg = alpha * (x-tf.abs(x))*.5\n",
    "        \n",
    "        return pos + neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrelu(x, alpha=0.3, name='lrelu'):\n",
    "    return tf.maximum(x, alpha * x, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bn(x,ri=[0,1,2],eps=.0001,scaling=True):\n",
    "    xshp=x.get_shape().as_list()\n",
    "    with tf.variable_scope('bn'):\n",
    "        mu = tf.reduce_mean(x,ri,keep_dims=True)\n",
    "        sigma = tf.reduce_mean(tf.square(x-mu),ri,keep_dims=True)\n",
    "        x_hat = (x-mu)/(tf.sqrt(sigma+eps))\n",
    "        \n",
    "        if scaling:\n",
    "            gamma = tf.get_variable('gamma',[xshp[-1]],initializer=tf.truncated_normal_initializer(0,.1))\n",
    "            beta = tf.get_variable('beta',[xshp[-1]],initializer=tf.constant_initializer(1.))\n",
    "            y = gamma*x_hat+beta\n",
    "        else:\n",
    "            y = x_hat\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = Batch(mapping=bin_mapping,bin_max=bin_size_x[1],batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = 'modelckpt/disc_raw.ckpt'\n",
    "tb_path = '../tb_logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32,shape=b.shape)\n",
    "    y = tf.placeholder(tf.float32,shape=b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    def Dis(x,reuse=False):\n",
    "        with tf.variable_scope('Discriminator') as scope:\n",
    "            if reuse:\n",
    "                scope.reuse_variables()\n",
    "            #Down Colnvolutions\n",
    "            #create variables\n",
    "            with tf.variable_scope('in'):\n",
    "                # Shape (height,width,inchannels,out_channels)\n",
    "                #down convolutions operations\n",
    "                with tf.variable_scope('l1'):\n",
    "                    dis_conv1=tf.get_variable('conv1',shape=[1,31,1,1],initializer=tf.truncated_normal_initializer(0,.02))\n",
    "                    dis_b1 = tf.get_variable('b1',shape=1,initializer=tf.constant_initializer(0.1))\n",
    "                    dis_l1=lrelu(bn(tf.nn.conv2d(x,dis_conv1,strides=[1,1,2,1],padding='SAME')+dis_b1))\n",
    "                with tf.variable_scope('l2'):\n",
    "                    dis_conv2=tf.get_variable('conv2',shape=[1,31,1,16],initializer=tf.truncated_normal_initializer(0,.02))\n",
    "                    dis_b2 = tf.get_variable('b2',shape=16,initializer=tf.constant_initializer(0.1))\n",
    "                    dis_l2=lrelu(bn(tf.nn.conv2d(dis_l1,dis_conv2,strides=[1,1,2,1],padding='SAME')+dis_b2))\n",
    "                with tf.variable_scope('l3'):\n",
    "                    dis_conv3=tf.get_variable('conv3',shape=[1,31,16,32],initializer=tf.truncated_normal_initializer(0,.02))\n",
    "                    dis_b3 = tf.get_variable('b3',shape=32,initializer=tf.constant_initializer(0.1))\n",
    "                    dis_l3=lrelu(bn(tf.nn.conv2d(dis_l2,dis_conv3,strides=[1,1,2,1],padding='SAME')+dis_b3))\n",
    "                with tf.variable_scope('l4'):\n",
    "                    dis_conv4=tf.get_variable('conv4',shape=[1,31,32,32],initializer=tf.truncated_normal_initializer(0,.02))\n",
    "                    dis_b4 = tf.get_variable('b4',shape=32,initializer=tf.constant_initializer(0.1))\n",
    "                    dis_l4=lrelu(bn(tf.nn.conv2d(dis_l3,dis_conv4,strides=[1,1,2,1],padding='SAME')+dis_b4))\n",
    "                with tf.variable_scope('l5'):\n",
    "                    dis_conv5=tf.get_variable('conv5',shape=[1,31,32,64],initializer=tf.truncated_normal_initializer(0,.02))\n",
    "                    dis_b5 = tf.get_variable('b5',shape=64,initializer=tf.constant_initializer(0.1))\n",
    "                    dis_l5=lrelu(bn(tf.nn.conv2d(dis_l4,dis_conv5,strides=[1,1,2,1],padding='SAME')+dis_b5))\n",
    "                with tf.variable_scope('l6'):\n",
    "                    dis_conv6=tf.get_variable('conv6',shape=[1,31,64,64],initializer=tf.truncated_normal_initializer(0,.02))\n",
    "                    dis_b6 = tf.get_variable('b6',shape=64,initializer=tf.constant_initializer(0.1))\n",
    "                    dis_l6=lrelu(bn(tf.nn.conv2d(dis_l5,dis_conv6,strides=[1,1,2,1],padding='SAME')+dis_b6))\n",
    "                with tf.variable_scope('l7'):\n",
    "                    dis_conv7=tf.get_variable('conv7',shape=[1,31,64,128],initializer=tf.truncated_normal_initializer(0,.02))\n",
    "                    dis_b7 = tf.get_variable('b7',shape=128,initializer=tf.constant_initializer(0.1))\n",
    "                    dis_l7=lrelu(bn(tf.nn.conv2d(dis_l6,dis_conv7,strides=[1,1,2,1],padding='SAME')+dis_b7))\n",
    "\n",
    "            dis_last_shape = dis_l7.get_shape()\n",
    "            dis_es=int(dis_last_shape[2])*int(dis_last_shape[3]) #size of encoding\n",
    "            dis_last = tf.reshape(bn(dis_l7),[b.batch_size,dis_es,1,1])\n",
    "            \n",
    "            with tf.variable_scope('final_conv'):\n",
    "                dis_conv_na = tf.get_variable('conv',shape=[1,1,1,1],initializer=tf.truncated_normal_initializer(0,.02))\n",
    "                dis_b_na = tf.get_variable('b',shape=[1],initializer=tf.constant_initializer(0.0))\n",
    "                dis_na=tf.nn.conv2d(dis_last,dis_conv_na,strides=[1,1,1,1],padding='SAME')+dis_b_na\n",
    "                dis_na = tf.reshape(dis_na,[b.batch_size,dis_es])\n",
    "                \n",
    "\n",
    "            #fully connected\n",
    "            with tf.variable_scope('fc'):\n",
    "                W_fc = tf.get_variable('W',shape=[dis_es,1],initializer=tf.truncated_normal_initializer(0.1))\n",
    "                b_fc = tf.get_variable('b',shape=[1],initializer=tf.constant_initializer(0.1))\n",
    "\n",
    "                #D_out = tf.sigmoid(bn(tf.matmul(dis_last,W_fc)+b_fc,ri=[0,1],scaling=True))\n",
    "                D_out = tf.matmul(dis_na,W_fc)+b_fc\n",
    "        return D_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    x_logit=Dis(x)\n",
    "    y_logit=Dis(y,reuse=True)\n",
    "    \n",
    "    x_pred = tf.sigmoid(x_logit)\n",
    "    y_pred = tf.sigmoid(y_logit)\n",
    "    \n",
    "    #early losses\n",
    "    loss1 = tf.reduce_mean(tf.square(x_logit)) #regularized loss for x\n",
    "    loss2 = tf.reduce_mean(tf.square(y_logit-1)) #regularized loss for y\n",
    "    loss_early = loss1+loss2\n",
    "    \n",
    "    #later\n",
    "    loss3 = tf.reduce_mean(tf.log(x_pred))\n",
    "    loss4 = tf.reduce_mean(tf.log(1-y_pred))\n",
    "    loss_later = loss3+loss4\n",
    "\n",
    "    #earlier optimizer\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=0.0002).minimize(loss_early)\n",
    "    \n",
    "    #late optimizer\n",
    "#     dvars = [e for e in g.get_collection('trainable_variables') if 'Discriminator' in e.name]\n",
    "#     # gradient clipping\n",
    "#     optimizer = tf.train.AdadeltaOptimizer(learning_rate=.0002)\n",
    "#     grad_d,var_d = zip(*optimizer.compute_gradients(loss_early,var_list=dvars))\n",
    "#     grad_d_clipped ,_= tf.clip_by_global_norm(grad_d,.5)\n",
    "#     opt_late=optimizer.apply_gradients(zip(grad_d_clipped,var_d))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    #tf.summary.scalar('max_gradient',tf.maximum(tf.abs(grad_d)))\n",
    "    tf.summary.scalar('Early_Discriminator_Loss',loss_early)\n",
    "    tf.summary.scalar('Later_Discriminator_Loss',loss_later)\n",
    "    tf.summary.histogram(\"X_Predictions\",x_pred)\n",
    "    tf.summary.histogram(\"Y_Predictions\",y_pred)\n",
    "    merged = tf.summary.merge_all()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session and writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.Session(graph=g)\n",
    "writer = tf.summary.FileWriter(tb_path,g)\n",
    "sess.run(init)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62725395],\n",
       "       [ 0.62858242],\n",
       "       [ 0.62901223],\n",
       "       [ 0.62931466],\n",
       "       [ 0.62942457],\n",
       "       [ 0.62984264],\n",
       "       [ 0.62975246],\n",
       "       [ 0.62826651],\n",
       "       [ 0.62843829],\n",
       "       [ 0.6310153 ],\n",
       "       [ 0.62489188],\n",
       "       [ 0.62999088],\n",
       "       [ 0.63052374],\n",
       "       [ 0.62933362],\n",
       "       [ 0.6278373 ],\n",
       "       [ 0.62826246],\n",
       "       [ 0.6299808 ],\n",
       "       [ 0.62826121],\n",
       "       [ 0.63038492],\n",
       "       [ 0.63164765],\n",
       "       [ 0.6301285 ],\n",
       "       [ 0.62965095],\n",
       "       [ 0.63072401],\n",
       "       [ 0.63483804],\n",
       "       [ 0.63027304],\n",
       "       [ 0.6283291 ],\n",
       "       [ 0.62875396],\n",
       "       [ 0.62768477],\n",
       "       [ 0.63116038],\n",
       "       [ 0.63011688],\n",
       "       [ 0.62994844],\n",
       "       [ 0.62904972]], dtype=float32)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data,y_data = b.getBatch()\n",
    "fd = {x:x_data,y:y_data}\n",
    "sess.run(y_pred,feed_dict=fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:25<00:00,  3.61it/s]\n"
     ]
    }
   ],
   "source": [
    "num_steps = 300\n",
    "save_step = 500\n",
    "for i in tqdm(xrange(num_steps)):\n",
    "    x_data,y_data = b.getBatch()\n",
    "    fd = {x:x_data,y:y_data}\n",
    "    _,l = sess.run([opt,loss_early],feed_dict=fd)\n",
    "#     _ = sess.run([opt_late],feed_dict=fd)\n",
    "    losses.append(l)\n",
    "    if i % 10 == 0:\n",
    "        summary = sess.run(merged,feed_dict = fd)\n",
    "        writer.add_summary(summary,i)\n",
    "    if i % save_step == 0:\n",
    "        save_path = saver.save(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f12be3cfd10>]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFWfQS1LFGfSSVHEGvSRVnEEvSRX3/wHR2StkwqqELQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f12c0f0c350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
